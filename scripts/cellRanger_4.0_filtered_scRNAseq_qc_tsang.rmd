---
title: "KC and PR scRNA-seq import of filtered 10x output and QC of placental villous tissue"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::knit_engines$set(python = reticulate::eng_python)

#install.packages("package_name",  repos="http://cran.us.r-project.org") # Only this mirror worked for multiple packages
library(ggpubr)
library(here)
library(knitr)
library(tidyverse)
library(devtools)
library(Seurat)
library(cowplot) 
library(rgl)
library(EnvStats)
library(Matrix)

# Bioconductor packages
library(DropletUtils)
library(edgeR)
library(scater)
```
### Important References
Minimal QC recommended: Current best practices in single‐cell RNA‐seq analysis: a tutorial
Orchestrating Single-cell Analysis
https://bioconductor.org/packages/release/bioc/vignettes/DropletUtils/inst/doc/DropletUtils.html
### Compiling Issues
This document had trouble compiling via knitr and pandoc. The following thread fixed the issue (https://github.com/rstudio/rstudio/issues/3661).

## Custom function to create list of Seurat objects from 10x output directories
```{r}
# Function to convert from 10x output to seurat object with no filtering
tenx_to_seu <- function(tenx_directory, name) {
  seu <- CreateSeuratObject(
    counts = Read10X(tenx_directory),
    project = name)
  return(seu)
}
```

## Unfiltered 10x output stats
Unfiltered 10x output data have been stored as dgCMatrix. Vector is all caps represent final columns for supplemental table. Chunk contains TOTAL.DROPLETS.RAW, TOTAL.RNA.RAW, TOTAL.GENES.RAW, FETAL.SEX.

```{r}
LIBRARY.ID <- c("1A", "1B", "2A", "2B", "3", "4", "5", "6", "7", "8C", "8P", "9C", "9P", "PE1", "PE2", "PE3", "PE4")
```

```{r, eval = F}
# Get raw 10X data directory
tenx.raw.out <- paste0(here("data", "tenx_unfiltered_data"), "/")
# Get filenames
names.raw <-
  grep(
    dir(
      path = tenx.raw.out             #list all files, unfortunately includes .ini files
      ),
    pattern = "(kc|tnl|tsang)",        #pattern to search for, excludes .ini files
    value = T                    #return matches
    )
# Get files 
files <-
  paste0(
    tenx.raw.out, 
    names.raw
  )
# Read files into R
raw.list <- lapply(files, function(x) readRDS(x))
# Rename according to naming convention
#LIBRARY.ID <- c("1A", "1B", "2A", "2B", "3", "4", "5", "6", "7", "8C", "8P", "9C", "9P", "PE1", "PE2", "PE3", "PE4")
names(raw.list) <- LIBRARY.ID
# Create a Seurat object out of each file
raw.seurat <- lapply(raw.list, function(x) CreateSeuratObject(counts = x))
# Clean-up memory
rm(raw.list)

# Get number of total droplets sequenced (always 737280)
TOTAL.DROPLETS.RAW <- lapply(raw.seurat, function(x) x %>% ncol()) %>% as.numeric
# Total unique RNA molecules
TOTAL.RNA.RAW <- lapply(raw.seurat, function(x) x$nCount_RNA %>% sum()) %>% as.numeric
# Total unique genes measured
TOTAL.GENES.RAW <- lapply(raw.seurat, function(x) x %>% nrow()) %>% as.numeric
# Sex of samples
FETAL.SEX <- c("F", "F", "M", "M", "M", "F", "M", "M", "M", "F", "F", "F", "F", "M", "M", "F", "F")
```
`


## Get list of droplet-called and filtered Seurat objects
Contains TOTAL.CELLS
```{r}
tenx_out <- paste0(here("data", "tenx_outs"), "/")
# Pull full file paths
names <- 
  grep(
    dir(
      path = tenx_out             #list all files, unfortunately includes .ini files
      ),
    pattern = "(kc|pr|tsang)", #pattern to search for, excludes .ini files
    value = T                    #return matches
    )
files <-
  paste0(
    tenx_out, 
    names
  )

# Create list of Seurat objects
counts <- map2(files, names, tenx_to_seu)
# Name list
names(counts) <- names
# Manually add batch metadata to distinguish kc from pr
counts$kc.40.1$'batch' <- "kc"
counts$kc.40.2$'batch' <- "kc"
counts$kc.42.1$'batch' <- "kc"
counts$kc.42.2$'batch' <- "kc"
counts$pr.478$'batch' <- "pr"
counts$pr.481$'batch' <- "pr"
counts$pr.484$'batch' <- "pr"
counts$tsang_n1$'batch' <- "tsang"
counts$tsang_n2$'batch' <- "tsang"
counts$tsang_n3c$'batch' <- "tsang"
counts$tsang_n3p$'batch' <- "tsang"
counts$tsang_n4c$'batch' <- "tsang"
counts$tsang_n4p$'batch' <- "tsang"
counts$tsang_pe1$'batch' <- "tsang"
counts$tsang_pe2$'batch' <- "tsang"
counts$tsang_pe3$'batch' <- "tsang"
counts$tsang_pe4$'batch' <- "tsang"
# Manually add bioreplicate metadata
counts$kc.40.1$'biorep' <- "kc.40"
counts$kc.40.2$'biorep' <- "kc.40"
counts$kc.42.1$'biorep' <- "kc.42"
counts$kc.42.2$'biorep' <- "kc.42"
counts$pr.478$'biorep' <- "pr.478"
counts$pr.481$'biorep' <- "pr.481"
counts$pr.484$'biorep' <- "pr.484"
counts$tsang_n1$'biorep' <- "tsang_n1"
counts$tsang_n2$'biorep' <- "tsang_n2"
counts$tsang_n3c$'biorep' <- "tsang_n3"
counts$tsang_n3p$'biorep' <- "tsang_n3"
counts$tsang_n4c$'biorep' <- "tsang_n4"
counts$tsang_n4p$'biorep' <- "tsang_n4"
counts$tsang_pe1$'biorep' <- "tsang_pe1"
counts$tsang_pe2$'biorep' <- "tsang_pe2"
counts$tsang_pe3$'biorep' <- "tsang_pe3"
counts$tsang_pe4$'biorep' <- "tsang_pe4"

TOTAL.CELLS <- lapply(counts, function(x) ncol(x)) %>% as.numeric()
```

## Create list of freemuxlet raw output data
```{r}
freemux_dir <- paste0(here("data", "freemuxlet", "raw_data"), "/")
names <- 
  grep(
    dir(
      path = freemux_dir             #list all files, unfortunately includes .ini files
      ),
    pattern = "(kc|pr|tsang)", #pattern to search for, excludes .ini files
    value = T                    #return matches
    )
files <-
  paste0(
    freemux_dir, 
    names
  )
# Read in freemuxlet dataframes, specifying the datatype in each column
freemux.clusters <- lapply(files, readr::read_tsv, col_types = "iciiffdfddddfdfddfdd")
names(freemux.clusters) <- names

# Optional 'QC' freemux output in freemuxlet_analysis_tsang.Rmd
```

TESTING
No na's among raw freemux data
```{r, eval = F}
freemux.clusters$tsang_n4p.clusters$BEST.GUESS %>% is.na %>% summary
lapply(freemux.clusters, function(x) x$BEST.GUESS %>% as.factor %>% is.na %>% summary)
```

## Custom function to add freemuxlet cluster assignment to Seurat MetaData
```{r}
# Add freemuxlet cluster assignment to Seurat Metadata
AddFreemuxletMetaData <- function(seu, freemux.data, col.name) {
  seu.barcodes <- tibble (
    BARCODE = rownames(seu@meta.data)) # get barcodes list from Seurat object
  join <- left_join(                      # join freemuxlet assignment with barcodes
    seu.barcodes,
    freemux.data %>%
      dplyr::select(BARCODE, BEST.GUESS) %>%
      mutate(
        BEST.GUESS = fct_recode(          # Refactor freemuxlet assignments
          BEST.GUESS,
          "1" = "1,1",
          "0" = "0,0",
          "doublet" = "1,0"
        )
      )
  )
  seu <- AddMetaData(seu,                 # Add MetaData to Seurat object
                     join %>% pull(BEST.GUESS),
                     col.name = col.name)
  return(seu)                             # Return augmented Seurat object
}
```

## Add freemuxlet cluster assignment to Seurat objects
Error output for pr.478 and n4p because it is the only dataset with no assigned doublets. Output appears normal otherwise
```{r}
mapped <-
  map2(counts,                              # List of Seurat objects
       freemux.clusters,                    # List of freemuxlet raw data
       AddFreemuxletMetaData,               # Function to call
       col.name = "freemuxlet.assignments") # Every metadata column has same name
```

```{r, eval = F}
lapply(mapped, function(x) dim(x@meta.data))
```

```{r, eval = F}
# Sum of mapped
#2573+2600+2544+2740+1907+2653+2456+6018+16968+4918+2284+3137+3612+13659+4025+8084+13149
# sum of all freemuxlet is 93009
#dim(all)
# Difference explains the 318 cells in the mapped dataset that are missing from the raw freemuxlet data
#93327-93009
# = 318
```

TESTING
Missing barcodes come from tsang_n1 and tsang_n2
```{r, eval = F}
lapply(mapped, function(x) x$freemuxlet.assignments %>% as.factor %>% is.na %>% summary)
```

```{r}
rm(counts)       # Remove data
rm(freemux.clusters) # Remove data
```

## Merge Seurat objects and remove doublets
Chunk contains FETAL.MATERNAL.DOUBLETS.REMOVED
```{r}
# Merge, adding cell id information because barcodes can and have been duplicated across experiments
kc.seu <- merge(x = mapped[[1]],                # Seurat object
             y = mapped[(2:4)],                  # List
             add.cell.ids = names(mapped)[1:4])   # Add cell IDs using names

# Identify number of cells removed for doublets
doublets.kc <- 
  kc.seu@meta.data %>%
  mutate(doublet = as.factor(freemuxlet.assignments)) %>%
  group_by(orig.ident, doublet) %>%
  tally() %>%
  filter(doublet == "doublet") %>%
  dplyr::select(n)
doublets.kc <- doublets.kc$n

# Remove doublets
kc.seu <- subset(x = kc.seu,
              subset = freemuxlet.assignments == "doublet",
              invert = T)

# Merge, adding cell id information because barcodes can and have been duplicated across experiments
pr.seu <- merge(x = mapped[[5]],                # Seurat object
             y = mapped[(6:7)],             # List
             add.cell.ids = names(mapped)[5:7])   # Add cell IDs using names

# Identify number of cells removed for doublets
doublets.pr <- 
  pr.seu@meta.data %>%
  mutate(doublet = as.factor(freemuxlet.assignments)) %>%
  group_by(orig.ident, doublet) %>%
  tally() %>%
  filter(doublet == "doublet") %>%
  dplyr::select(n)
doublets.pr <- c(0, doublets.pr$n)

pr.seu <- subset(x = pr.seu,
              subset = freemuxlet.assignments == "doublet",
              invert = T)

# Merge, adding cell id information because barcodes can and have been duplicated across experiments
tsang.seu <- merge(x = mapped[[8]],                # Seurat object
             y = mapped[(9:17)],                  # List
             add.cell.ids = names(mapped)[8:17])   # Add cell IDs using names

# Identify number of cells removed for doublets
doublets.tsang <- 
  tsang.seu@meta.data %>%
  mutate(doublet = as.factor(freemuxlet.assignments)) %>%
  group_by(orig.ident, doublet) %>%
  tally() %>%
  filter(doublet == "doublet") %>%
  dplyr::select(n)
doublets.tsang <- doublets.tsang$n

# Manually add 0 doublets removed for sample tsang_n4p, similar to pr 478
doublets.tsang <- c(doublets.tsang[1], doublets.tsang[2], doublets.tsang[3], doublets.tsang[4], 0, doublets.tsang[5],
                    doublets.tsang[6], doublets.tsang[7], doublets.tsang[8], doublets.tsang[9])

# Remove doublets and droplets that were dropped from pileup
tsang.seu <- subset(x = tsang.seu,
              subset = freemuxlet.assignments == "doublet" | is.na(freemuxlet.assignments),
              invert = T)

FETAL.MATERNAL.DOUBLETS.REMOVED <- c(doublets.kc, doublets.pr, doublets.tsang)
```

# QC by batch and merge

Initial analysis was too strict for KC batch; a lib.size cutoff of 500 (happens with CellRanger barcode calling), like the other samples appears appropriate w/ diagnostic plots. Will rely on NMAD to do mitochondrial cutoffs for all samples (double-check this is okay for KC); will impose minimum 200 gene detected cutoff for all samples, which is consistent with previous analysis of PR and checks out with QC plots.

https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/algorithms/overview#cell_calling for additional reading about cell calling

## This section merges and uses fixed thresholds and compares merged adaptive thresholds; not used for the final analytic sample

```{r, eval = F}
sce <- cbind(as.SingleCellExperiment(kc.seu), as.SingleCellExperiment(pr.seu), as.SingleCellExperiment(tsang.seu))
sce$sample <- factor(sce$ident, labels = LIBRARY.ID)
sce$batch <- as.factor(sce$batch)
#sce <- sce[, !(sce$orig.ident %in% c("tsang_pe1" ,"tsang_pe2", "tsang_pe3", "tsang_pe4")) ,drop=TRUE]
```

```{r, eval = F}
# Find mitochondrial genes
is.mito <- grepl("^MT-", rownames(sce))
# Add per cell QC metrics to the object
sce <- addPerCellQC(sce, subsets = list(Mito=is.mito))

sce.rna.threshold <- 500
sce.gene.threshold <- 200
sce.mito.threshold <- 10

qc.lib <- sce$sum < sce.rna.threshold
qc.nexprs <- sce$detected < sce.gene.threshold
qc.mito <- sce$subsets_Mito_percent > sce.mito.threshold
discard <- qc.lib | qc.nexprs | qc.mito
sce$discard <- discard

# Summarize the number of cells removed for each reason.
DataFrame(LibSize=sum(qc.lib), NExprs=sum(qc.nexprs), MitoProp=sum(qc.mito), Total=sum(discard))
```

Adaptive threhsolds (nMADs = 3)
```{r, eval = F}
# Create QC data frame
qc.df <- perCellQCMetrics(sce, subsets = list(Mito=is.mito))
# Reasons for exclusion, considering batch
batch.reasons <- quickPerCellQC(qc.df, batch=sce$batch,
                                sub.fields = "subsets_Mito_percent",
                                nmads = 3)
colSums(as.matrix(batch.reasons))

# Add discard metadata to object
# With fixed thresholds
#sce$discard <- discard

# With adaptive thresholds
#sce$discard <- batch.reasons$discard
#discard <- batch.reasons$discard
```

```{r, eval = F}
plotColData(sce, x="sum", y="subsets_Mito_percent", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = sce.rna.threshold, linetype = "dashed") +
  geom_hline(yintercept = sce.mito.threshold, linetype = "dashed") +
  xlab("Library Size") + ylab("Mitochondrial Gene Mapping Rate (%)")
plotColData(sce, x="detected", y="subsets_Mito_percent", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = sce.gene.threshold, linetype = "dashed") +
  geom_hline(yintercept = sce.mito.threshold, linetype = "dashed") +
  xlab("Genes Detected") + ylab("Mitochondrial Gene Mapping Rate (%)")
plotColData(sce, x="sum", y="detected", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = sce.rna.threshold, linetype = "dashed") +
  geom_hline(yintercept = sce.gene.threshold, linetype = "dashed") +
  xlab("Library Size") + ylab("Genes Detected")
```

Subset to QC-filtered cells.
```{r, eval = F}
# Keeping the columns we DON'T want to discard.
filtered <- sce[,!discard]
dropped <- as.numeric(summary(discard)["TRUE"])
kept <- as.numeric(summary(discard)["FALSE"])
print(paste0(dropped, " cells were filtered, yielding ", kept, " remaining cells"))
```

Identify if a rare cell type might have been discarded.
```{r, eval = F}
lost <- calculateAverage(counts(sce)[,!discard])
kept <- calculateAverage(counts(sce)[,discard])

logged <- edgeR::cpm(cbind(lost, kept), log=TRUE, prior.count=2)
logFC <- logged[,1] - logged[,2]
abundance <- rowMeans(logged)
```

Blue points are mitochondrial genes and are expected to be downregulated. Exclusion of a cell type may be indicated by overexpression on this plot, of which there does not appear to be strong overexpression.
```{r, eval = F}
plot(abundance, logFC, xlab="Average count", ylab="Log-FC (lost/kept)", pch=16)
points(abundance[is.mito], logFC[is.mito], col="dodgerblue", pch=16)
```

Looks like only RBCs have been differentially removed via QC
```{r, eval = F}
# Pull out differentially regulated genes
logFC[logFC < -2]
```

# KC QC
```{r}
# Convert to SingleCellExperiment for QC
sce.kc <- as.SingleCellExperiment(kc.seu)
# Factorize the batch variable
sce.kc$batch <- as.factor(sce.kc$batch)
```

## Droplet Calling
Skipping droplet calling since 10x already filters that under Cell Ranger 4.0 based on Aaron Lun's EmptyDroplets().

## Calculate QC Metrics
Lib.size = 500
Genes = 200
Mito % = nmad 4

Increased NMADs to 4 because NMAD of 3.0 looks too restrictive for KC data. Looks like an appropriate compromise based on QC plots.
```{r}
# Find mitochondrial genes
is.mito <- grepl("^MT-", rownames(sce.kc))
# Add per cell QC metrics to the object
sce.kc <- addPerCellQC(sce.kc, subsets = list(Mito=is.mito))

# Create QC data frame
qc.df <- perCellQCMetrics(sce.kc, subsets = list(Mito=is.mito))
# Reasons for exclusion, considering batch
batch.reasons <- quickPerCellQC(qc.df, batch=sce.kc$batch,
                                sub.fields = "subsets_Mito_percent",
                                nmads = 4)
colSums(as.matrix(batch.reasons))

# Verifying NMADs are calculated correctly manually for learning purposes
# See http://bioconductor.org/books/3.14/OSCA.basic/quality-control.html#common-choices-of-qc-metrics for further discussion of MAD
# Performed on the log scale to avoid negative values, and backtransform the result for plotting
#sce.kc.rna.threshold = exp(median(log(sce.kc$sum)) - 4*mad(log(sce.kc$sum)))
#sce.kc.gene.threshold = exp(median(log(sce.kc$detected)) - 4*mad(log(sce.kc$detected)))
#sce.kc.mito.threshold = median(sce.kc$subsets_Mito_percent) + 4*mad(sce.kc$subsets_Mito_percent)

#sce.kc.rna.threshold
#sce.kc.gene.threshold
#sce.kc.mito.threshold

# The actual set of functions to retrieve the adaptive thresholds; matches those manually calculated above (commented out)
sce.kc.rna.threshold <- attr(batch.reasons$low_lib_size, "thresholds")[1]
sce.kc.gene.threshold <- attr(batch.reasons$low_n_features, "thresholds")[1]
sce.kc.mito.threshold <- attr(batch.reasons$high_subsets_Mito_percent, "thresholds")[2]

# Add adaptive thresholds metadata to object
sce.kc$rna.threshold <- sce.kc.rna.threshold
sce.kc$gene.threshold <- sce.kc.gene.threshold
sce.kc$mito.threshold <- sce.kc.mito.threshold

# Set lib.size and n.detected thresholds, pull adaptive mito threshold
lib.size.cutoff <- 500
gene.det.cutoff <- 200
qc.lib <- sce.kc$sum < lib.size.cutoff
qc.nexprs <- sce.kc$detected < gene.det.cutoff
qc.mito <- sce.kc$subsets_Mito_percent > sce.kc.mito.threshold
discard <- qc.lib | qc.nexprs | qc.mito

# Summarize the number of cells removed for each reason using the fixed thresholds above, not used
DataFrame(LibSize=sum(qc.lib), NExprs=sum(qc.nexprs), MitoProp=sum(qc.mito), Total=sum(discard))

# Add discard metadata to object with fixed thresholds, not used
sce.kc$discard <- discard
```

QC plots.
```{r}
plotColData(sce.kc, x="sum", y="subsets_Mito_percent", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = lib.size.cutoff, linetype = "dashed") +
  geom_hline(yintercept = sce.kc.mito.threshold, linetype = "dashed")
plotColData(sce.kc, x="detected", y="subsets_Mito_percent", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = gene.det.cutoff, linetype = "dashed") +
  geom_hline(yintercept = sce.kc.mito.threshold, linetype = "dashed")
plotColData(sce.kc, x="sum", y="detected", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = lib.size.cutoff, linetype = "dashed") +
  geom_hline(yintercept = gene.det.cutoff, linetype = "dashed") 
```

```{r}
plotColData(sce.kc, x="ident", y="sum", colour_by="discard") + 
        scale_y_log10() + ggtitle("Total count")
plotColData(sce.kc, x="ident", y="detected", colour_by="discard") + 
        scale_y_log10() + ggtitle("Detected features")
plotColData(sce.kc, x="ident", y="subsets_Mito_percent", 
        colour_by="discard") + ggtitle("Mito percent")
```

Exploratory investigation of variance explained by metadata.
```{r}
#vars <- getVarianceExplained(logNormCounts(sce.kc), 
#    variables=c("ident", "subsets_Mito_percent", "sum", "detected"))
#plotExplanatoryVariables(vars)
```

Subset to QC-filtered cells.
```{r}
# Keeping the columns we DON'T want to discard.
filtered <- sce.kc[,!discard]
dropped <- as.numeric(summary(discard)["TRUE"])
kept <- as.numeric(summary(discard)["FALSE"])
print(paste0(dropped, " cells were filtered, yielding ", kept, " remaining cells"))
```

Identify if a rare cell type might have been discarded.
```{r}
lost <- calculateAverage(counts(sce.kc)[,!discard])
kept <- calculateAverage(counts(sce.kc)[,discard])

logged <- edgeR::cpm(cbind(lost, kept), log=TRUE, prior.count=2)
logFC <- logged[,1] - logged[,2]
abundance <- rowMeans(logged)
```

Blue points are mitochondrial genes and are expected to be downregulated. Exclusion of a cell type may be indicated by overexpression on this plot, of which there does not appear to be strong overexpression.
```{r}
plot(abundance, logFC, xlab="Average count", ylab="Log-FC (lost/kept)", pch=16)
points(abundance[is.mito], logFC[is.mito], col="dodgerblue", pch=16)
```
Even at NMAD = 4, CSH1 is differentially underexpressed, indicates omission of syncytiotrophoblasts, possibly correct since syncytiotrophoblast may have been differentially technically less sound.
```{r}
# Pull out differentially regulated genes
logFC[logFC < -2]

plotExpression(sce.kc, features = "CSH1", x = "subsets_Mito_percent")
plotExpression(filtered, features = "CSH1", x = "subsets_Mito_percent")

plotExpression(sce.kc, features = "CSH1", x = "total")
plotExpression(filtered, features = "CSH1", x = "total")

plotExpression(sce.kc, features = "CSH1", x = "detected")
plotExpression(filtered, features = "CSH1", x = "detected")
```

Convert to Seurat object for further preprocessing and analysis and save.
```{r}
kc <- as.Seurat(filtered)
#saveRDS(kc, paste0(data_dir, "placenta_scRNA_seq_kc_filtered_", Sys.Date(), ".rda"))
```

Explore batch effect in KC samples. There doesn't appear to be much of a batch effect.
```{r, eval = F}
# Should normalize and find variable features in each dataset separately
kc <- NormalizeData(object = kc, normalization.method = "LogNormalize", scale.factor = 10000)
kc <- FindVariableFeatures(object = kc)
kc <- ScaleData(kc)
kc <- RunPCA(kc, features = VariableFeatures(object = kc))
ElbowPlot(object = kc, ndims = 100)
DimPlot(kc, reduction = "pca", group.by = 'orig.ident')
DimPlot(kc, reduction = "pca", group.by = 'biorep')
```

# Pique-Regi data QC

```{r}
# Convert to SingleCellExperiment for QC
sce.pr <- as.SingleCellExperiment(pr.seu)
# Factorize the batch variable
sce.pr$batch <- as.factor(sce.pr$batch)
# Clean-up memory
# rm(seu)
```

## Droplet Calling
Skipping droplet calling since 10x already filters that under Cell Ranger 4.0 based on Aaron Lun's EmptyDroplets().

## Calculate QC Metrics
Default NMAD of 3 Looks like an appropriate level for the PR data based on QC plots.
Lib.size = 500
Genes = 200
Mito % = nmad 3
```{r}
# Find mitochondrial genes
is.mito <- grepl("^MT-", rownames(sce.pr))
# Add per cell QC metrics to the object
sce.pr <- addPerCellQC(sce.pr, subsets = list(Mito=is.mito))

# Create QC data frame
qc.df <- perCellQCMetrics(sce.pr, subsets = list(Mito=is.mito))
# Reasons for exclusion, considering batch
batch.reasons <- quickPerCellQC(qc.df, batch=sce.pr$batch,
                                sub.fields = "subsets_Mito_percent",
                                nmads = 3)
colSums(as.matrix(batch.reasons))

# The actual set of functions to retrieve the adaptive thresholds; matches those manually calculated above (commented out)
sce.pr.rna.threshold <- attr(batch.reasons$low_lib_size, "thresholds")[1]
sce.pr.gene.threshold <- attr(batch.reasons$low_n_features, "thresholds")[1]
sce.pr.mito.threshold <- attr(batch.reasons$high_subsets_Mito_percent, "thresholds")[2]

# Add adaptive thresholds metadata to object
sce.pr$rna.threshold <- sce.pr.rna.threshold
sce.pr$gene.threshold <- sce.pr.gene.threshold
sce.pr$mito.threshold <- sce.pr.mito.threshold

# Set lib.size and n.detected thresholds, pull adaptive mito threshold
lib.size.cutoff <- 500
gene.det.cutoff <- 200
qc.lib <- sce.pr$sum < lib.size.cutoff
qc.nexprs <- sce.pr$detected < gene.det.cutoff
qc.mito <- sce.pr$subsets_Mito_percent > sce.pr.mito.threshold
discard <- qc.lib | qc.nexprs | qc.mito

# Summarize the number of cells removed for each reason using the fixed thresholds above, not used
DataFrame(LibSize=sum(qc.lib), NExprs=sum(qc.nexprs), MitoProp=sum(qc.mito), Total=sum(discard))

# Add discard metadata to object with fixed thresholds, not used
sce.pr$discard <- discard
```

QC plots.
```{r}
plotColData(sce.pr, x="sum", y="subsets_Mito_percent", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = lib.size.cutoff, linetype = "dashed") +
  geom_hline(yintercept = sce.pr.mito.threshold, linetype = "dashed")
plotColData(sce.pr, x="detected", y="subsets_Mito_percent", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = gene.det.cutoff, linetype = "dashed") +
  geom_hline(yintercept = sce.pr.mito.threshold, linetype = "dashed")
plotColData(sce.pr, x="sum", y="detected", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = lib.size.cutoff, linetype = "dashed") +
  geom_hline(yintercept = gene.det.cutoff, linetype = "dashed") 
```

```{r}
plotColData(sce.pr, x="ident", y="sum", colour_by="discard") + 
        scale_y_log10() + ggtitle("Total count")
plotColData(sce.pr, x="ident", y="detected", colour_by="discard") + 
        scale_y_log10() + ggtitle("Detected features")
plotColData(sce.pr, x="ident", y="subsets_Mito_percent", 
        colour_by="discard") + ggtitle("Mito percent")
```
Exploratory investigation of variance explained by metadata.
```{r}
#vars <- getVarianceExplained(logNormCounts(sce.pr), 
#    variables=c("ident", "subsets_Mito_percent", "sum", "detected"))
#plotExplanatoryVariables(vars)
```

Subset to QC-filtered cells.
```{r}
# Keeping the columns we DON'T want to discard.
filtered <- sce.pr[,!discard]
dropped <- as.numeric(summary(discard)["TRUE"])
kept <- as.numeric(summary(discard)["FALSE"])
print(paste0(dropped, " cells were filtered, yielding ", kept, " remaining cells"))
```

Identify if a rare cell type might have been discarded.
```{r}
lost <- calculateAverage(counts(sce.pr)[,!discard])
kept <- calculateAverage(counts(sce.pr)[,discard])

logged <- edgeR::cpm(cbind(lost, kept), log=TRUE, prior.count=2)
logFC <- logged[,1] - logged[,2]
abundance <- rowMeans(logged)
```

Blue points are mitochondrial genes and are expected to be downregulated. Exclusion of a cell type may be indicated by overexpression on this plot, of which there does not appear to be strong overexpression.
```{r}
plot(abundance, logFC, xlab="Average count", ylab="Log-FC (lost/kept)", pch=16)
points(abundance[is.mito], logFC[is.mito], col="dodgerblue", pch=16)
```

No clear cell types omitted based on my prior knowledge.
```{r}
logFC[logFC < -2]
```

Convert to Seurat object for further preprocessing and analysis and save.
```{r}
pr <- as.Seurat(filtered)
```

Explore batch effect in PR samples. There may be some batch effect in 481 (4) compared to 478 (3) and 484 (5)
```{r, eval = F}
# Should normalize and find variable features in each dataset separately
pr <- NormalizeData(object = pr, normalization.method = "LogNormalize", scale.factor = 10000)
pr <- FindVariableFeatures(object = pr)
pr <- ScaleData(pr)
pr <- RunPCA(pr, features = VariableFeatures(object = pr))
ElbowPlot(object = pr, ndims = 100)
DimPlot(pr, reduction = "pca", group.by = 'orig.ident')
```

# Tsang QC
```{r}
# Convert to SingleCellExperiment for QC
sce.tsang <- as.SingleCellExperiment(tsang.seu)
# Factorize the batch variable
sce.tsang$batch <- as.factor(sce.tsang$batch)
# Subset to healthy samples
sce.tsang <- sce.tsang[, !(sce.tsang$orig.ident %in% c("tsang_pe1" ,"tsang_pe2", "tsang_pe3", "tsang_pe4")) ,drop=TRUE]
```

## Droplet Calling
Skipping droplet calling since 10x already filters that under Cell Ranger 4.0 based on Aaron Lun's EmptyDroplets().

## Calculate QC Metrics
Default NMAD of 3 Looks like an appropriate level fro the Tsang data based on QC plots.
Lib.size = 500
Genes = 200
Mito % = nmad 3
```{r}
# Find mitochondrial genes
is.mito <- grepl("^MT-", rownames(sce.tsang))
# Add per cell QC metrics to the object
sce.tsang <- addPerCellQC(sce.tsang, subsets = list(Mito=is.mito))

# Create QC data frame
qc.df <- perCellQCMetrics(sce.tsang, subsets = list(Mito=is.mito))
# Reasons for exclusion, considering batch
batch.reasons <- quickPerCellQC(qc.df, batch=sce.tsang$batch,
                                sub.fields = "subsets_Mito_percent",
                                nmads = 3)
colSums(as.matrix(batch.reasons))

# The actual set of functions to retrieve the adaptive thresholds; matches those manually calculated above (commented out)
sce.tsang.rna.threshold <- attr(batch.reasons$low_lib_size, "thresholds")[1]
sce.tsang.gene.threshold <- attr(batch.reasons$low_n_features, "thresholds")[1]
sce.tsang.mito.threshold <- attr(batch.reasons$high_subsets_Mito_percent, "thresholds")[2]

# Add adaptive thresholds metadata to object
sce.tsang$rna.threshold <- sce.tsang.rna.threshold
sce.tsang$gene.threshold <- sce.tsang.gene.threshold
sce.tsang$mito.threshold <- sce.tsang.mito.threshold

# Set lib.size and n.detected thresholds, pull adaptive mito threshold
lib.size.cutoff <- 500
gene.det.cutoff <- 200
qc.lib <- sce.tsang$sum < lib.size.cutoff
qc.nexprs <- sce.tsang$detected < gene.det.cutoff
qc.mito <- sce.tsang$subsets_Mito_percent > sce.tsang.mito.threshold
discard <- qc.lib | qc.nexprs | qc.mito

# Summarize the number of cells removed for each reason using the fixed thresholds above, not used
DataFrame(LibSize=sum(qc.lib), NExprs=sum(qc.nexprs), MitoProp=sum(qc.mito), Total=sum(discard))

# Add discard metadata to object with fixed thresholds, not used
sce.tsang$discard <- discard

#seu.sce.tsang <- as.Seurat(sce.tsang)
#seu.sce.tsang@meta.data %>% rownames_to_column(var = "cell.id") %>% mutate(filtered.in.error = ifelse(cell.id %in% filtered.in.error, T, F)) %>% View
```

QC plots.
```{r}
plotColData(sce.tsang, x="sum", y="subsets_Mito_percent", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = lib.size.cutoff, linetype = "dashed") +
  geom_hline(yintercept = sce.tsang.mito.threshold, linetype = "dashed")
plotColData(sce.tsang, x="detected", y="subsets_Mito_percent", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = gene.det.cutoff, linetype = "dashed") +
  geom_hline(yintercept = sce.tsang.mito.threshold, linetype = "dashed")
plotColData(sce.tsang, x="sum", y="detected", colour_by = "discard") + scale_x_log10() +
  geom_vline(xintercept = lib.size.cutoff, linetype = "dashed") +
  geom_hline(yintercept = gene.det.cutoff, linetype = "dashed") 
```

```{r}
plotColData(sce.tsang, x="ident", y="sum", colour_by="discard") + 
        scale_y_log10() + ggtitle("Total count")
plotColData(sce.tsang, x="ident", y="detected", colour_by="discard") + 
        scale_y_log10() + ggtitle("Detected features")
plotColData(sce.tsang, x="ident", y="subsets_Mito_percent", 
        colour_by="discard") + ggtitle("Mito percent")
```
Exploratory investigation of variance explained by metadata.
```{r}
#vars <- getVarianceExplained(logNormCounts(sce.tsang), 
#    variables=c("ident", "subsets_Mito_percent", "sum", "detected"))
#plotExplanatoryVariables(vars)
```
Subset to QC-filtered cells. There appears to be many more cells in the Tsang dataset; however, a similar number of cells (~10%) are filtered based on similar QC metrics.
```{r}
# Keeping the columns we DON'T want to discard.
filtered <- sce.tsang[,!discard]
dropped <- as.numeric(summary(discard)["TRUE"])
kept <- as.numeric(summary(discard)["FALSE"])
print(paste0(dropped, " cells were filtered, yielding ", kept, " remaining cells"))
```
Identify if a rare cell type might have been discarded.
```{r}
lost <- calculateAverage(counts(sce.tsang)[,!discard])
kept <- calculateAverage(counts(sce.tsang)[,discard])

logged <- edgeR::cpm(cbind(lost, kept), log=TRUE, prior.count=2)
logFC <- logged[,1] - logged[,2]
abundance <- rowMeans(logged)
```

Blue points are mitochondrial genes and are expected to be downregulated. Exclusion of a cell type may be indicated by overexpression on this plot, of which there does not appear to be strong overexpression.
```{r}
plot(abundance, logFC, xlab="Average count", ylab="Log-FC (lost/kept)", pch=16)
points(abundance[is.mito], logFC[is.mito], col="dodgerblue", pch=16)
```
Similar differentially expressed genes based on kept/discarded cells as previous samples (lots of MT)
```{r}
# Pull out differentially expressed genes
logFC[logFC < -2]
```

Convert to Seurat object for further preprocessing and analysis and save.
```{r}
tsang <- as.Seurat(filtered)
#saveRDS(tsang, paste0(data_dir, "placenta_scRNA_seq_tsang_filtered_", Sys.Date(), ".rda"))
```

Explore batch effect in tsang samples. There doesn't appear to be much of a batch effect.
```{r, eval = F}
# Should normalize and find variable features in each dataset separately
tsang <- NormalizeData(object = tsang, normalization.method = "LogNormalize", scale.factor = 10000)
tsang <- FindVariableFeatures(object = tsang)
tsang <- ScaleData(tsang)
tsang <- RunPCA(tsang, features = VariableFeatures(object = tsang))
ElbowPlot(object = tsang, ndims = 100)
DimPlot(tsang, reduction = "pca", group.by = 'orig.ident')
DimPlot(tsang, reduction = "pca", group.by = 'biorep')
```

```{r, eval = F, include = F}
kc.raw <- lapply(raw.seurat[1:4], function(x) x$nCount_RNA) %>% unlist
pr.raw <- lapply(raw.seurat[5:7], function(x) x$nCount_RNA) %>% unlist
tsang.raw <- lapply(raw.seurat[7:13], function(x) x$nCount_RNA) %>% unlist

hist(log(kc.raw[kc.raw >= 20]))
exp(6)
log(500)
```

## QC stats filtering reporting

Merge with cbind
```{r}
sce <- cbind(sce.kc, sce.pr, sce.tsang)
sce$sample <- factor(sce$ident, labels = LIBRARY.ID[1:13])
```

Number and average number of cells QC-filtered
```{r}
# 46,991 included
sum(table(sce$discard, sce$sample)[1,1:13])
# 3,614.69 per sample 
sum(table(sce$discard, sce$sample)[1,1:13])/13
# 6,365 excluded
sum(table(sce$discard, sce$sample)[2,1:13])
# 489.62 per sample
sum(table(sce$discard, sce$sample)[2,1:13])/13
```

```{r, eval = F}
sce.meta <- data.frame(
  LIBRARY.ID = sce$sample,
  rna = sce$sum,
  genes = sce$detected,
  mito = sce$subsets_Mito_percent,
  discard = sce$discard
)

qc.supp <- 
  sce.meta %>%
  group_by(LIBRARY.ID) %>%
  summarize(RNA.MOLECULES.MEDIAN = median(rna),
            RNA.MOLECULES.IQR = ceiling(iqr(rna)),
            GENES.MEDIAN = median(genes),
            GENES.IQR = ceiling(iqr(genes)),
            MITO.PERCENT.MEDIAN = round(median(mito), digits = 2),
            MITO.PERCENT.IQR = round(iqr(mito), digits = 2))
cell.count.post.filter <-
  sce.meta %>% 
  group_by(LIBRARY.ID) %>%
  filter(discard == F) %>%
  tally()

qc.supp$CELL.COUNT <- cell.count.post.filter$n

qc.prefilter <- data.frame(LIBRARY.ID, FETAL.SEX, TOTAL.DROPLETS.RAW, TOTAL.RNA.RAW, TOTAL.GENES.RAW, TOTAL.CELLS, FETAL.MATERNAL.DOUBLETS.REMOVED)

QC <- left_join(qc.prefilter, qc.supp)
colnames(QC) <- c("Sample", "Fetal Sex", "Droplets Sequenced", "Total Unique RNA Molecules", "Total Unique Genes Detected", "Total Cells", "Maternal/Fetal Doublets Removed", "Unique RNA Molecules, Median", "Unique RNA Molecules, IQR", "Unique Genes, Median", "Unique Genes, IQR", "Percent Mitochondrial Gene Expression, Median", "Percent Mitochondrial Gene Expression, IQR", "Cells in Final Analytic Sample")

#write.table(x = QC, file = here("results", "single_cell_qc", "scrna_qc_summary.csv"), row.names = F, sep = ",")
```

```{r}
base.size <- 24

rna.vln <- plotColData(sce, x="sample", y="sum", colour_by="discard") + 
  scale_y_log10() + ggtitle("Total unique RNA molecules") + theme_bw(base_size = base.size) +
  theme(legend.position = "bottom") +
  guides(colour = guide_legend(override.aes = list(size=20), reverse = TRUE))
#ggsave(here("results", "single_cell_qc", paste0(Sys.Date(), "rna_molecules_by_rep.png")))

gene.vln <- plotColData(sce, x="sample", y="detected", colour_by="discard") + 
        scale_y_log10() + ggtitle("Detected genes") + theme_bw(base_size = base.size)
#ggsave(here("results", "single_cell_qc", paste0(Sys.Date(), "genes_detected_by_rep.png")))

mito.vln <- plotColData(sce, x="sample", y="subsets_Mito_percent", 
        colour_by="discard") + ggtitle("Mitochondrial Gene Mapping Rate (%)") + ylab("percentage") + theme_bw(base_size = base.size)
#ggsave(here("results", "single_cell_qc", paste0(Sys.Date(), "percent_mito_by_rep.png")))

legend <- get_legend(rna.vln)
```

```{r}
panel <- ggarrange(rna.vln, gene.vln, mito.vln, ncol = 3, nrow = 1, labels = "AUTO", font.label = list(size = 40, face = "bold", color = "black"), common.legend = TRUE, legend = "bottom", legend.grob = legend)
#ggexport(panel, filename = here("results", "single_cell_qc", paste0(Sys.Date(), "_qc_vlns.png")), width = 1980, height = 1080)
```

```{r}
seu <- subset(as.Seurat(sce), subset = discard == F)
```

Proceed with updated QC thresholds for resubmit (keep mito% nmads and impose lib.size < 500 and gene < 200)
```{r}
#saveRDS(seu, here("data", "analytic", "post_qc", paste0("kc_pr_tsang_qc_merged_", Sys.Date(), ".rda")))
```


Looks like merging causes duplicate metadata columns
```{r}
# Load in the fully annotated kc, pr Seurat object
kc.pr.analyzed.seu <- readRDS(here("data", "cleaned_combined_seurat_2020-12-22.rda"))
DimPlot(kc.pr.analyzed.seu, group.by = 'cell.type', split.by = "fetal", label = T, repel = T) + NoLegend()
```

```{r}
merged <- merge(kc.pr.analyzed.seu, tsang)
#saveRDS(merged, here("data", paste0("kcprfinal_tsang_qc_merged_", Sys.Date(), ".rda")))
```